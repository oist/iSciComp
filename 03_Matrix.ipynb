{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Vectors and Matrices\n",
    "Computational Methods, Oct. 2022, Kenji Doya\n",
    "\n",
    "Here we work with vectors and matrices, and get acquainted with concepts in linear algebra by computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ % Latex macros\n",
    "\\newcommand{\\mat}[1]{\\begin{pmatrix} #1 \\end{pmatrix}}\n",
    "\\newcommand{\\p}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\b}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\w}{\\boldsymbol{w}}\n",
    "\\newcommand{\\x}{\\boldsymbol{x}}\n",
    "\\newcommand{\\y}{\\boldsymbol{y}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy *ndarray* as vector and matrix\n",
    "You can create a matrix from a nested list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You cam also create a matrix by stacking arrays vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([1, 2, 3])\n",
    "np.vstack((b, 2*b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# another way of stacking row vectors\n",
    "np.r_[[b, 2*b]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or by combining arrays as column vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.c_[b, 2*b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create an arbitrary matrix by list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[10*i + j for j in range(3)] for i in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are functions and attributes to check the type and shape of a vector or matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(A)  # in the outmost level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape  # each dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.size  # total items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.ndim  # dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 2D numpy array is internally a linear sequence of data.  \n",
    "`ravel( )` geves its flattened representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of reshaping reflect this internal sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.reshape(3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can excange rows and columns by transpose `.T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adressing components by [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[1]  # second row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[:,1]  # second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[:,::-1]  # columns in reverse order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify arbitrary order by a list of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[[1,0,1]]  # rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[:, [1,2,1,0]]  # columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[[1,0,1], [1,2,0]]   # [A[1,1], A[0,2], A[1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(2,3)  # normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random(size=(2,3))  # uniform in [0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform(-1, 1, (2,3))  # uniform in [-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(-3, 3, size=(2,3))  # integers -3,...,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.empty((2,3), dtype=int)  # allocate without initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Vectors and dot product\n",
    "A vector can represent:\n",
    "* a point in n-dimensional space\n",
    "* a movement in n-dimensional space\n",
    "\n",
    "The dot product (or inner product) of two vectors\n",
    "$\\b{x} = (x_1,...,x_n)$ and $\\b{y} = (y_1,...,y_n)$\n",
    "is defined as  \n",
    "\n",
    "$$ \\b{x} \\cdot \\b{y} = x_1 y_1 + ... + x_n y_n = \\sum_{i=1}^n x_i y_i $$  \n",
    "\n",
    "The inner product measures how two vectors match up, giving\n",
    "\n",
    "$$ -||\\b{x}||\\,||\\b{y}|| \\le \\b{x} \\cdot \\b{y} \\le ||\\b{x}||\\,||\\b{y}|| $$\n",
    "\n",
    "with the maximum when two vectors line up, zero when two are orthogonal.\n",
    "\n",
    "The length (or norm) of the vector is defined as  \n",
    "\n",
    "$$ ||\\b{x}|| = \\sqrt{\\sum_{i=1}^n x_i^2} = \\sqrt{\\b{x} \\cdot \\b{x}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0, 1, 2])\n",
    "y = np.array([3, 4, 5])\n",
    "print( x * y)  # component-wise product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different ways to compute a dot product of vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.inner(x, y))\n",
    "print( np.dot(x, y))\n",
    "print( x.dot(y))\n",
    "print( x @ y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices and matrix product\n",
    "A matrix can represent\n",
    "* a set of vectors\n",
    "* time series of vectors\n",
    "* 2D image data,\n",
    "* ...\n",
    "\n",
    "The matrix product $AB$ is a matrix made of the inner products of the rows of $A$ and the columns of $B$.  \n",
    "For \n",
    "$A = \\left(\\begin{array}{cc} a & b\\\\ c & d\\end{array}\\right)$\n",
    "and \n",
    "$B = \\left(\\begin{array}{cc} e & f\\\\ g & h\\end{array}\\right)$,\n",
    "the matrix product is \n",
    "\n",
    "$$ AB = \\left(\\begin{array}{cc} ae+bg & af+bh \\\\ ce+dg & cf+dh\\end{array}\\right). $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0, 1], [2, 3]])\n",
    "print(A)\n",
    "B = np.array([[3, 2], [1, 0]])\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( A * B)  # component-wise\n",
    "print( np.inner(A, B))  # row by row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways for a matrix product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.dot(A, B))\n",
    "print( A.dot(B))\n",
    "print( A @ B)  # new since Pyton 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix and vector space\n",
    "\n",
    "A matrix product can mean:\n",
    "* transformation to another vector space\n",
    "* movement in the space\n",
    "\n",
    "The product of a 2D matrix $A$ and a vector $\\b{x}$ is given as\n",
    "\n",
    "$$ A \\b{x} = \\mat{ a & b\\\\ c & d}\\mat{x \\\\ y} = \\mat{ax+by\\\\ cx+dy}. $$\n",
    "\n",
    "Specifically for unit vectors\n",
    "\n",
    "$$ A \\mat{1 \\\\ 0} = \\mat{ a \\\\ c } \\mbox{and } A \\mat{0 \\\\ 1} = \\mat{ b \\\\ d}$$\n",
    "\n",
    "meaning that each column of $A$ represents how a unit vector in each axis is transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a set of points in colors\n",
    "s = 2  # grid size\n",
    "x = np.arange(-s, s+1)\n",
    "X1, X2 = np.meshgrid(x, x)\n",
    "# 2xm matrix of points\n",
    "X = np.vstack((np.ravel(X1), np.ravel(X2)))\n",
    "print(X)\n",
    "# red-blue for x, green for y\n",
    "C = (np.vstack((X[0,:], X[1,:], -X[0,:])).T + s)/(2*s)\n",
    "plt.scatter(X[0,:], X[1,:], c=C)\n",
    "p = plt.axis('square')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how those points are transformed by a matrix\n",
    "a = 1\n",
    "A = np.random.random((2, 2))*2*a - a   # uniform in [-a, a]\n",
    "print(A)\n",
    "AX = A @ X\n",
    "plt.scatter(AX[0,:], AX[1,:], c=C)\n",
    "p = plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determinant and inverse\n",
    "The transformed space are expanded, shrunk, or flattened.  \n",
    "The *determinant* of a square matrix measures the expansion of the volume.  \n",
    "For a 2 by 2 matrix\n",
    "$A = \\left(\\begin{array}{cc} a & b\\\\ c & d\\end{array}\\right)$,  \n",
    "the determinant is computed by\n",
    "\n",
    "$$\\det A = ad - bc.$$\n",
    "\n",
    "You can use `linalg.det()` for any matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "np.linalg.det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\det A \\ne 0$, a matrix is called *regular*, *non-singular*, or *invertible*.\n",
    "\n",
    "The inverse $A^{-1}$ of a square matrix $A$ is defined as a matrix satisfying  \n",
    "$$ AX = XA = I $$\n",
    "where $I$ is the identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ainv = np.linalg.inv(A)\n",
    "print(Ainv)\n",
    "print( A @ Ainv)\n",
    "print( Ainv @ A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving linear algebraic equations\n",
    "Many problems are formed as a set of linear equations:\n",
    "\n",
    "$$ a_{11}x_1 + a_{12}x_2 + \\cdots + a_{1n}x_n = b_1 $$\n",
    "\n",
    "$$ \\vdots $$\n",
    "\n",
    "$$ a_{m1}x_1 + a_{m2}x_2 + \\cdots + a_{mn}x_n = b_m $$\n",
    "\n",
    "This can be expressed by a matrix-vector equation\n",
    "\n",
    "$$ A\\b{x} =\\b{b} $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ A = \\left(\\begin{array}{ccc} a_{11} & \\cdots & a_{1n}\\\\\n",
    "    \\vdots &  & \\vdots\\\\\n",
    "    a_{m1} & \\cdots & a_{mn}\\end{array}\\right), \\quad\n",
    "   \\b{x} = \\left(\\begin{array}{c} x_1\\\\ \\vdots\\\\ x_n\\end{array}\\right), \\quad\n",
    "   \\b{b} = \\left(\\begin{array}{c} b_1\\\\ \\vdots\\\\ b_m\\end{array}\\right). $$\n",
    "   \n",
    "If $m=n$ and $A$ is regular, the solution is given by \n",
    "\n",
    "$$ \\b{x} = A^{-1} \\b{b}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1., 2], [3, 4]])\n",
    "b = np.array([1, 0])\n",
    "Ainv = np.linalg.inv(A)\n",
    "print(\"Ainv =\", Ainv)\n",
    "x = Ainv @ b\n",
    "print('x = Ainv b =', x)\n",
    "print('Ax =', A @ x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $A^{-1}$ is used just once, it is more efficient to use a linear euqation solver function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linalg.solve(A, b)\n",
    "print('x = ', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalues and eigenvectors\n",
    "With a transformation by a symmetrix matrix $A$, some vectors keep its own direction. Such a vector is called an *eigenvector* and its scaling coefficient is called the *eigenvalue*.  \n",
    "Eigenvalues and eigenvectors are derived by solving the equation\n",
    "\n",
    "$$ A\\b{x} = \\lambda \\b{x} $$\n",
    "\n",
    "which is equivalent to $ A\\b{x} - \\lambda \\b{x} = (A - \\lambda I)\\b{x} = 0.$  \n",
    "Eigenvalues are derived by solving a polynomial equation\n",
    "\n",
    "$$ \\det (A - \\lambda I) = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `linalg.eig()` function to numerically derive eigenvalues $\\b{\\lambda} = (\\lambda_1,...,\\lambda_n)$ and a matrix of eigenvectors in columns $V = (\\b{v}_1,...,\\b{v}_n)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [1, 0.5]])\n",
    "print(A)\n",
    "lam, V = np.linalg.eig(A)\n",
    "print(lam)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colorful grid from above\n",
    "AX = A @ X\n",
    "plt.scatter(AX[0,:], AX[1,:], c=C)\n",
    "# Plot eiven vectors scaled by eigen values\n",
    "for i in range(2):\n",
    "    plt.plot( [0, lam[i]*V[0,i]], [0, lam[i]*V[1,i]], 'o-', lw=3)\n",
    "p = plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigendecomposition\n",
    "\n",
    "For a square matrix $A$, consider a matrix consisting of its eigenvalues on the diagonal\n",
    "\n",
    "$$ \\Lambda = \\mbox{diag}(\\lambda_1, \\cdots, \\lambda_n) $$\n",
    "\n",
    "and another matrix made of their eigenvectors in columns\n",
    "\n",
    "$$ V = (\\b{v}_1, \\cdots, \\b{v}_n). $$\n",
    "\n",
    "From\n",
    "\n",
    "$$ AV = (\\lambda_1 \\b{v}_1, \\cdots, \\lambda_n \\b{v}_n)\n",
    " = (\\b{v}_1, \\cdots, \\b{v}_n)\n",
    "   \\mat{\\lambda_1 & & \\\\ & \\ddots & \\\\ & & \\lambda_n}\n",
    " = V \\Lambda, $$\n",
    "\n",
    "if $V$ is invertible, $A$ can be represented as\n",
    "\n",
    "$$ A = V \\Lambda V^{-1}. $$\n",
    "\n",
    "This representation of a matrix is called *eigendecomposition* or *spectral decomposition*.\n",
    "\n",
    "This representation is extremely useful in multiplying $A$ many times as \n",
    "\n",
    "$$ A^k = V \\Lambda^k V^{-1} = V \\mbox{diag}(\\lambda_1^k, \\cdots, \\lambda_n^k) V^{-1} $$\n",
    "\n",
    "requires only exponentials in the diagonal terms rather than repeated matrix multiplications.\n",
    "\n",
    "It also helps intutitive understanding of how a point $\\b{x}$ transofrmed by $A$ many times as $A\\b{x}, A^2\\b{x}, A^3\\b{x},...$ would move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance matrix\n",
    "For $m$ samples of $n$-dimensional variable \n",
    "$ \\b{x} = (x_1,..., x_n)$\n",
    "we usuall create a data matrix \n",
    "\n",
    "$$ X = \\left(\\begin{array}{ccc} x_1^1 & \\cdots & x^1_n\\\\\n",
    "    \\vdots &  & \\vdots\\\\\n",
    "    x^m_1 & \\cdots & x^m_n\\end{array}\\right).$$  \n",
    "\n",
    "The covariance $c_{ij}$ of the components $x_i$ and $x_j$ represents how the two variables change togher around the mean:\n",
    "\n",
    "$$ \\bar{x}_i = \\frac{1}{m} \\sum_{k=1}^m x_i^k $$\n",
    "\n",
    "$$ c_{ij} = \\frac{1}{m-1} \\sum_{k=1}^m (x_i^k - \\bar{x}_i)(x_j^k - \\bar{x}_j) $$\n",
    "\n",
    "The covariance matrix $C$ consists of the covariances of all pairs of components\n",
    "\n",
    "$$ C = \\begin{pmatrix} c_{11} & \\cdots & c_{1n}\\\\\n",
    "    \\vdots &  & \\vdots\\\\\n",
    "    c_{n1} & \\cdots & c_{nn}\\end{pmatrix}\n",
    "    = \\frac{1}{m-1} \\sum_{k=1}^m (\\b{x}^k - \\bar{\\b{x}})^T(\\b{x}^k - \\bar{\\b{x}}) $$\n",
    "\n",
    "where $\\bar{x}$ is the mean vector\n",
    "\n",
    "$$ \\bar{\\b{x}} = (\\bar{x}_1,..., \\bar{x}_n) = \\frac{1}{m} \\sum_{j=1}^m \\b{x}^k\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the iris data\n",
    "# X = np.loadtxt('data/iris.txt', delimiter=',')\n",
    "# Y = X[:,-1]  # flower type\n",
    "# X = X[:,:4]\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "m, n = X.shape\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X[:,0], X[:,1], c=Y, marker='.')\n",
    "plt.axis('square')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X[:,2], X[:,3], c=Y, marker='.')\n",
    "plt.axis('square');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbar = np.mean(X, axis=0)\n",
    "print(\"xbar =\", xbar)\n",
    "dX = X - xbar  # deviation from the mean\n",
    "C = (dX.T @ dX)/(m-1)\n",
    "print(\"C =\", C)\n",
    "# or using the built-in function\n",
    "np.cov(X, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal component analysis (PCA)\n",
    "In taking a grasp of high-dimensional data, it is often useful to project the data onto a subspace where the data vary most.\n",
    "\n",
    "To do that, we first take the covariance matrix $C$ of the data, compute its eigenvalues $\\lambda_i$ and eigenvectors $\\b{v}_i$, and project the data onto the subspace  spanned by the eigenvectors with largest eigen values.  \n",
    "The eigenvectors $\\b{v}_i$ of the covariance matrix is called *principal component vectors*, ordered by the magnitude of their eigenvalues.\n",
    "\n",
    "Each data point $\\b{x}$ is projected to the principal component vectors \n",
    "$(\\b{v}_1\\cdot\\b{x}, \\b{v}_2\\cdot\\b{x},...)$ for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam, V = np.linalg.eig(C)\n",
    "print('lam, V = ', lam, V)\n",
    "# it is not guaranteed that the eigenvalues are sorted, so sort them\n",
    "ind = np.argsort(-lam)  # indices for sorting, descending order\n",
    "lams = lam[ind]\n",
    "Vs = V[:,ind]\n",
    "print('lams, Vs = ', lams, Vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see the principal component vectors in the original space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = np.zeros(n)\n",
    "# first two components\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(dX[:,0], dX[:,1], c=Y, marker='.')\n",
    "for i in range(4):\n",
    "    plt.plot( [0, lams[i]*Vs[0,i]], [0, lams[i]*Vs[1,i]], 'o-', lw=2)\n",
    "plt.setp(plt.gca(), xlabel='X0', ylabel='X1')\n",
    "plt.axis('square')\n",
    "# last two components\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(dX[:,2], dX[:,3], c=Y, marker='.')\n",
    "for i in range(4):\n",
    "    plt.plot( [0, lams[i]*Vs[2,i]], [0, lams[i]*Vs[3,i]], 'o-', lw=2)\n",
    "plt.setp(plt.gca(), xlabel='X2', ylabel='X3')\n",
    "plt.axis('square')\n",
    "plt.tight_layout()  # adjust space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us project the 4D data onto the space spanned by the eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = dX @ Vs\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(Z[:,0], Z[:,1], c=Y, marker='.')\n",
    "plt.setp(plt.gca(), xlabel='PC1', ylabel='PC2')\n",
    "plt.axis('square')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(Z[:,2], Z[:,3], c=Y, marker='.')\n",
    "plt.setp(plt.gca(), xlabel='PC3', ylabel='PC4')\n",
    "plt.axis('square')\n",
    "plt.tight_layout()  # adjust space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular value decomposition (SVD)\n",
    "For a $(m\\times n)$ matrix $A$, a non-negative value $\\sigma>0$ satisfying\n",
    "\n",
    "$$ A \\b{v} = \\sigma \\b{u}$$\n",
    "\n",
    "$$ A^T \\b{u} = \\sigma \\b{v}$$\n",
    "\n",
    "for unit vectors $||\\b{u}||=||\\b{v}||=1$ is called the *singular value*.   \n",
    "$\\b{u}$ and $\\b{v}$ are called left- and right-singular vectors.\n",
    "\n",
    "Singular value decomposition (SVD) of a $(m\\times n)$ matrix $A$ is\n",
    "\n",
    "$$ A = U S V^T = \\sum_i \\sigma_i \\b{u}_i \\b{v}_i^T $$\n",
    "\n",
    "where $S=\\mbox{diag}(\\sigma_1,...,\\sigma_k)$ is a diagonal matrix made of $k=\\min(m,n)$ singular values,  \n",
    "$U=(\\b{u}_1,...,\\b{u}_k)$ is a matrix made of orthogonal left-singular vectors, \n",
    "and $V=(\\b{v}_1,...,\\b{v}_k)$ is a matrix made of orthogonal right-singular vectors.\n",
    "\n",
    "SVD represents a matrix by a weighted sum of outer products of column vectors $\\b{u}_i$ and row vectors $\\b{v}_i$, such as spatial patterns mixed by different time courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = np.array([[0,1,2,3,4], [5,4,3,2,1], [1,3,2,4,3]])\n",
    "print(A)\n",
    "U, S, Vt = np.linalg.svd(A, full_matrices=False)\n",
    "#V = Vt.T\n",
    "print(U, S, Vt)\n",
    "U @ np.diag(S) @ Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,4,1)\n",
    "plt.imshow(A)\n",
    "plt.title('A ='); plt.axis('off')\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(U)\n",
    "plt.title('U'); plt.axis('off')\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(np.diag(S))\n",
    "plt.title('S'); plt.axis('off')\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(Vt)\n",
    "plt.title('V$^T$'); plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "for i in range(k):\n",
    "    plt.subplot(1,k,i+1)\n",
    "    plt.imshow(np.outer(U[:,i], Vt[i,:]))\n",
    "    plt.title('$u_{0} v^T_{0}$'.format(i))\n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA by SVD\n",
    "From $X = U SV^T$ and the orothonormal construction of $U$ and $V$, we can see\n",
    "\n",
    "$$C = \\frac{1}{m-1}X^T X = \\frac{1}{m-1}V S^2 V^T$$\n",
    "\n",
    "and\n",
    "\n",
    "$$C\\b{v}_i = \\frac{1}{m-1}\\sigma_i^2\\b{v}_i.$$ \n",
    "\n",
    "Thus columns of $V$ are principal component vectors and $\\frac{\\sigma_i^2}{m-1}$ are their eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris data\n",
    "print('by covariance:', lams, Vs)  # computed by eig of covariance matrix\n",
    "U, S, Vt = np.linalg.svd(dX, full_matrices=False)\n",
    "print('by SVD:', S**2/(m-1), Vt.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Eigen values of a 2x2 matrix\n",
    "\n",
    "Let us take the simplest and the most important case of 2 by 2 matrix\n",
    "\n",
    "$$ A = \\pmatrix{a & b \\\\ c & d}. $$\n",
    "\n",
    "We can analytically derive the eivenvalues from \n",
    "\n",
    "$$ \\det (A - \\lambda I) = (a-\\lambda)(d-\\lambda) - bc = 0 $$\n",
    "\n",
    "as\n",
    "\n",
    "$$ \\lambda = \\frac{a+d}{2} \\pm \\sqrt{\\frac{(a-d)^2}{4}+ bc}. $$\n",
    "\n",
    "The correctponding eigenvectors are not unique, but given by, for example, \n",
    "\n",
    "$$ \\b{x} = \\mat{b \\\\ \\lambda - a}. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real eigenvalues\n",
    "\n",
    "When $\\frac{(a-d)^2}{4}+ bc \\ge 0$, $A$ has two real eigenvalues\n",
    "$\\{\\lambda_1, \\lambda_2\\}$ \n",
    "with corresponding eigenvectors\n",
    "$\\{ \\b{v}_1, \\b{v}_2 \\}$ \n",
    "\n",
    "The movement of a point $\\b{x}$ by $A$ as \n",
    "$A\\b{x}, A^2\\b{x}, A^3\\b{x},...$ is composed of movements in the directions of the eigenvectors $\\{ \\b{v}_1, \\b{v}_2 \\}$.\n",
    "It is convergent if $|\\lambda_i|<1$\n",
    "and divergent if  $|\\lambda_i|>1.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a 2x2 matrix\n",
    "A = np.array([[1.5, 0.5], [1, 1]])\n",
    "# check the eigenvalues and eigenvectors\n",
    "L, V = np.linalg.eig(A)\n",
    "print(\"L =\", L)\n",
    "print(\"V = \", V)\n",
    "# take a point and see how it moves\n",
    "K = 7  # steps\n",
    "x = np.zeros((2, K))\n",
    "x[:,0] = [-2, 5]\n",
    "for k in range(K-1):\n",
    "    x[:,k+1] = A @ x[:,k]  # x_{k+1} = A x_k\n",
    "# plot the trajectory\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot( x[0], x[1], 'o-')\n",
    "plt.axis('square'); plt.xlabel(\"x1\"); plt.ylabel(\"x2\");\n",
    "# In the eigenspace\n",
    "y = np.zeros((2, K))\n",
    "y[:,0] = np.linalg.inv(V) @ x[:,0] # map to eigenspace\n",
    "for k in range(K-1):\n",
    "    y[:,k+1] = L*y[:,k]  # z_{k+1} = L z_k\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot( y[0], y[1], 'r+-')\n",
    "plt.axis('square'); plt.xlabel(\"v1\"); plt.ylabel(\"v2\");\n",
    "# Conver back to the original space\n",
    "plt.subplot(1,2,1)\n",
    "xv = (V @ y).real\n",
    "plt.plot( xv[0], xv[1], 'r+')\n",
    "plt.tight_layout();  # adjust the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex eigenvalues\n",
    "\n",
    "When $\\frac{(a-d)^2}{4}+ bc < 0$, $A$ has a pair of complex eigenvalues\n",
    "\n",
    "$$ \\lambda_1 = \\alpha + i\\beta \\mbox{ and } \\lambda_2 = \\alpha - i\\beta $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\alpha = \\frac{a+d}{2} \\mbox{ and } \\beta^2 = -\\frac{(a-d)^2}{4}- bc $$\n",
    "\n",
    "with corresponding eigenvectors\n",
    "\n",
    "$$ V = (\\b{v}_1, \\b{v}_2) = (\\b{u}+i\\b{w}, \\b{u}-i\\b{w}).$$ \n",
    "\n",
    "By eigendecomposition\n",
    "$ A = V \\Lambda V^{-1}, $\n",
    "a point $\\b{x}$ is converted to points in a complex plane and multipled by a complex eigenvalue, which means rotation and scaling.\n",
    "Points in the complex plane are then converted back in a real vector spce by multiplication with $V$.\n",
    "\n",
    "To see the rotation and scaling more explicityly, we can represent $\\Lambda=\\mat{\\alpha+i\\beta & 0 \\\\ 0 & \\alpha-i\\beta}$ as \n",
    "\n",
    "$$\\Lambda = U R U^{-1}$$ \n",
    "\n",
    "where $R$ is \n",
    "\n",
    "$$ R = \\mat{\\alpha & -\\beta \\\\ \\beta & \\alpha}\n",
    " = \\mat{r\\cos\\theta & -r\\sin\\theta \\\\ r\\sin\\theta & r\\cos\\theta }.$$\n",
    " \n",
    "Here $r=|\\lambda|=\\sqrt{\\alpha^2+\\beta^2}$ is the scaling factor and $\\theta$ is the angle of rotation.\n",
    "\n",
    "We can choose $U$ as \n",
    "\n",
    "$$ U = \\frac{1}{2}\\mat{1 & i \\\\ 1 & -i} $$\n",
    "\n",
    "such that \n",
    "$VU = (\\b{u}, -\\b{w})$.\n",
    "Then we have another decomposition of $A$ as\n",
    "\n",
    "$$ A = V \\Lambda V^{-1}\n",
    " = V URU^{-1} V^{-1}\n",
    " = (\\b{u}, -\\b{w}) \\mat{r\\cos\\theta & -r\\sin\\theta \\\\ r\\sin\\theta & r\\cos\\theta} (\\b{u}, -\\b{w})^{-1} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a 2x2 matrix\n",
    "A = np.array([[1, -1], [1, 0.5]])\n",
    "# check the eigenvalues and eigenvectors\n",
    "L, V = np.linalg.eig(A)\n",
    "print(\"L =\", L)\n",
    "print(\"V = \", V)\n",
    "# take a point and see how it moves\n",
    "K = 7  # steps\n",
    "x = np.zeros((2, K))\n",
    "x[:,0] = [1, 0]\n",
    "for k in range(K-1):\n",
    "    x[:,k+1] = A @ x[:,k]  # x_{k+1} = A x_k\n",
    "# plot the trajectory\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot( x[0], x[1], 'o-')\n",
    "plt.axis('square'); plt.xlabel(\"x1\"); plt.ylabel(\"x2\");\n",
    "# In the eigenspace\n",
    "z = np.zeros((2, K), dtype=complex)\n",
    "z[:,0] = np.linalg.inv(V) @ x[:,0]\n",
    "for k in range(K-1):\n",
    "    z[:,k+1] = L*z[:,k]  # z_{k+1} = L z_k\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot( z[0].real, z[0].imag, 'r+-')\n",
    "plt.plot( z[1].real, z[1].imag, 'm+-')\n",
    "plt.axis('square'); plt.xlabel(\"Real\"); plt.ylabel(\"Imag\");\n",
    "# In the cos-sin space\n",
    "VU = np.c_[V[:,0].real, -V[:,0].imag]\n",
    "R = np.array([[L[0].real, -L[0].imag], [L[0].imag, L[0].real]])\n",
    "print(\"R =\", R)\n",
    "print(\"VU =\", VU) \n",
    "y = np.zeros((2, K))\n",
    "y[:,0] = np.linalg.inv(VU) @ x[:,0]\n",
    "for k in range(K-1):\n",
    "    y[:,k+1] = R @ y[:,k]  # y_{k+1} = R y_k\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot( y[0], y[1], 'g*-')\n",
    "plt.axis('square'); plt.xlabel(\"u\"); plt.ylabel(\"-w\");\n",
    "# Conver back to the original space\n",
    "plt.subplot(1,3,1)\n",
    "xc = (V @ z).real\n",
    "xr = VU @ y\n",
    "plt.plot( xr[0], xr[1], 'g*')\n",
    "plt.plot( xc[0], xc[1], 'r+')\n",
    "plt.tight_layout(rect=[0, 0, 1.5, 1]);  # fit in extra width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The trajectory in the complex space or the $(\\b{u},-\\b{w})$ space is a regular spirals, which is mapped to a skewed spiral in the original space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
